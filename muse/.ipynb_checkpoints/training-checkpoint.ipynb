{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcab1591-efb0-4f9d-a7e9-daa4e4489d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f4670b5-580f-4dd1-a82b-fedc4b7e07dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch0_mean</th>\n",
       "      <th>ch0_std</th>\n",
       "      <th>ch0_range</th>\n",
       "      <th>ch0_delta</th>\n",
       "      <th>ch0_theta</th>\n",
       "      <th>ch0_alpha</th>\n",
       "      <th>ch0_beta</th>\n",
       "      <th>ch0_gamma</th>\n",
       "      <th>ch0_beta_alpha_ratio</th>\n",
       "      <th>ch0_theta_alpha_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>ch4_std</th>\n",
       "      <th>ch4_range</th>\n",
       "      <th>ch4_delta</th>\n",
       "      <th>ch4_theta</th>\n",
       "      <th>ch4_alpha</th>\n",
       "      <th>ch4_beta</th>\n",
       "      <th>ch4_gamma</th>\n",
       "      <th>ch4_beta_alpha_ratio</th>\n",
       "      <th>ch4_theta_alpha_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39.081573</td>\n",
       "      <td>12.873992</td>\n",
       "      <td>61.523438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.851588</td>\n",
       "      <td>21.446754</td>\n",
       "      <td>9.723149</td>\n",
       "      <td>13.656038</td>\n",
       "      <td>0.453362</td>\n",
       "      <td>2.184554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-37.227631</td>\n",
       "      <td>13.884357</td>\n",
       "      <td>66.406250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.072577</td>\n",
       "      <td>14.803212</td>\n",
       "      <td>6.943239</td>\n",
       "      <td>7.626599</td>\n",
       "      <td>0.469036</td>\n",
       "      <td>2.166596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-34.767151</td>\n",
       "      <td>16.858122</td>\n",
       "      <td>87.890625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.094227</td>\n",
       "      <td>17.629103</td>\n",
       "      <td>7.657607</td>\n",
       "      <td>7.025549</td>\n",
       "      <td>0.434373</td>\n",
       "      <td>2.217596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-28.472900</td>\n",
       "      <td>14.586349</td>\n",
       "      <td>87.890625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.059626</td>\n",
       "      <td>14.626256</td>\n",
       "      <td>25.088838</td>\n",
       "      <td>10.495665</td>\n",
       "      <td>1.715329</td>\n",
       "      <td>1.371481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-24.723053</td>\n",
       "      <td>12.084479</td>\n",
       "      <td>60.546875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.774399</td>\n",
       "      <td>11.005708</td>\n",
       "      <td>22.372438</td>\n",
       "      <td>10.381601</td>\n",
       "      <td>2.032803</td>\n",
       "      <td>1.796740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>-28.774261</td>\n",
       "      <td>24.532882</td>\n",
       "      <td>94.726562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.727390</td>\n",
       "      <td>34.518932</td>\n",
       "      <td>35.727990</td>\n",
       "      <td>14.153667</td>\n",
       "      <td>1.035026</td>\n",
       "      <td>3.120821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>-30.544281</td>\n",
       "      <td>24.638541</td>\n",
       "      <td>94.726562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.577154</td>\n",
       "      <td>40.077727</td>\n",
       "      <td>28.129601</td>\n",
       "      <td>11.797667</td>\n",
       "      <td>0.701876</td>\n",
       "      <td>3.881886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-30.185699</td>\n",
       "      <td>24.519231</td>\n",
       "      <td>94.726562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.969303</td>\n",
       "      <td>58.371875</td>\n",
       "      <td>44.510926</td>\n",
       "      <td>10.083179</td>\n",
       "      <td>0.762541</td>\n",
       "      <td>3.528571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-34.175873</td>\n",
       "      <td>34.708590</td>\n",
       "      <td>194.824219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.456512</td>\n",
       "      <td>56.180190</td>\n",
       "      <td>35.829245</td>\n",
       "      <td>18.415697</td>\n",
       "      <td>0.637756</td>\n",
       "      <td>3.301102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-46.909332</td>\n",
       "      <td>50.691238</td>\n",
       "      <td>211.425781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696.317715</td>\n",
       "      <td>291.979467</td>\n",
       "      <td>40.345864</td>\n",
       "      <td>21.784602</td>\n",
       "      <td>0.138180</td>\n",
       "      <td>2.384817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ch0_mean    ch0_std   ch0_range  ch0_delta   ch0_theta   ch0_alpha  \\\n",
       "0    -39.081573  12.873992   61.523438        0.0   46.851588   21.446754   \n",
       "1    -37.227631  13.884357   66.406250        0.0   32.072577   14.803212   \n",
       "2    -34.767151  16.858122   87.890625        0.0   39.094227   17.629103   \n",
       "3    -28.472900  14.586349   87.890625        0.0   20.059626   14.626256   \n",
       "4    -24.723053  12.084479   60.546875        0.0   19.774399   11.005708   \n",
       "...         ...        ...         ...        ...         ...         ...   \n",
       "1228 -28.774261  24.532882   94.726562        0.0  107.727390   34.518932   \n",
       "1229 -30.544281  24.638541   94.726562        0.0  155.577154   40.077727   \n",
       "1230 -30.185699  24.519231   94.726562        0.0  205.969303   58.371875   \n",
       "1231 -34.175873  34.708590  194.824219        0.0  185.456512   56.180190   \n",
       "1232 -46.909332  50.691238  211.425781        0.0  696.317715  291.979467   \n",
       "\n",
       "       ch0_beta  ch0_gamma  ch0_beta_alpha_ratio  ch0_theta_alpha_ratio  ...  \\\n",
       "0      9.723149  13.656038              0.453362               2.184554  ...   \n",
       "1      6.943239   7.626599              0.469036               2.166596  ...   \n",
       "2      7.657607   7.025549              0.434373               2.217596  ...   \n",
       "3     25.088838  10.495665              1.715329               1.371481  ...   \n",
       "4     22.372438  10.381601              2.032803               1.796740  ...   \n",
       "...         ...        ...                   ...                    ...  ...   \n",
       "1228  35.727990  14.153667              1.035026               3.120821  ...   \n",
       "1229  28.129601  11.797667              0.701876               3.881886  ...   \n",
       "1230  44.510926  10.083179              0.762541               3.528571  ...   \n",
       "1231  35.829245  18.415697              0.637756               3.301102  ...   \n",
       "1232  40.345864  21.784602              0.138180               2.384817  ...   \n",
       "\n",
       "      ch4_std  ch4_range  ch4_delta  ch4_theta  ch4_alpha  ch4_beta  \\\n",
       "0         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "2         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "3         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "...       ...        ...        ...        ...        ...       ...   \n",
       "1228      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1229      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1230      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1231      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1232      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "      ch4_gamma  ch4_beta_alpha_ratio  ch4_theta_alpha_ratio  label  \n",
       "0           0.0                   0.0                    0.0    0.0  \n",
       "1           0.0                   0.0                    0.0    0.0  \n",
       "2           0.0                   0.0                    0.0    0.0  \n",
       "3           0.0                   0.0                    0.0    0.0  \n",
       "4           0.0                   0.0                    0.0    0.0  \n",
       "...         ...                   ...                    ...    ...  \n",
       "1228        0.0                   0.0                    0.0    0.0  \n",
       "1229        0.0                   0.0                    0.0    0.0  \n",
       "1230        0.0                   0.0                    0.0    0.0  \n",
       "1231        0.0                   0.0                    0.0    0.0  \n",
       "1232        0.0                   0.0                    0.0    0.0  \n",
       "\n",
       "[1233 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"eeg_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6265cdbf-9a32-4925-b613-7c989c2857f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "...     ...\n",
       "1228    0.0\n",
       "1229    0.0\n",
       "1230    0.0\n",
       "1231    0.0\n",
       "1232    0.0\n",
       "\n",
       "[1233 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = df[[\"label\"]]\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e871669-a6c0-49f6-bcff-adaf0c79dc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch0_mean</th>\n",
       "      <th>ch0_std</th>\n",
       "      <th>ch0_range</th>\n",
       "      <th>ch0_delta</th>\n",
       "      <th>ch0_theta</th>\n",
       "      <th>ch0_alpha</th>\n",
       "      <th>ch0_beta</th>\n",
       "      <th>ch0_gamma</th>\n",
       "      <th>ch0_beta_alpha_ratio</th>\n",
       "      <th>ch0_theta_alpha_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>ch4_mean</th>\n",
       "      <th>ch4_std</th>\n",
       "      <th>ch4_range</th>\n",
       "      <th>ch4_delta</th>\n",
       "      <th>ch4_theta</th>\n",
       "      <th>ch4_alpha</th>\n",
       "      <th>ch4_beta</th>\n",
       "      <th>ch4_gamma</th>\n",
       "      <th>ch4_beta_alpha_ratio</th>\n",
       "      <th>ch4_theta_alpha_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39.081573</td>\n",
       "      <td>12.873992</td>\n",
       "      <td>61.523438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.851588</td>\n",
       "      <td>21.446754</td>\n",
       "      <td>9.723149</td>\n",
       "      <td>13.656038</td>\n",
       "      <td>0.453362</td>\n",
       "      <td>2.184554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-37.227631</td>\n",
       "      <td>13.884357</td>\n",
       "      <td>66.406250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.072577</td>\n",
       "      <td>14.803212</td>\n",
       "      <td>6.943239</td>\n",
       "      <td>7.626599</td>\n",
       "      <td>0.469036</td>\n",
       "      <td>2.166596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-34.767151</td>\n",
       "      <td>16.858122</td>\n",
       "      <td>87.890625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.094227</td>\n",
       "      <td>17.629103</td>\n",
       "      <td>7.657607</td>\n",
       "      <td>7.025549</td>\n",
       "      <td>0.434373</td>\n",
       "      <td>2.217596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-28.472900</td>\n",
       "      <td>14.586349</td>\n",
       "      <td>87.890625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.059626</td>\n",
       "      <td>14.626256</td>\n",
       "      <td>25.088838</td>\n",
       "      <td>10.495665</td>\n",
       "      <td>1.715329</td>\n",
       "      <td>1.371481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-24.723053</td>\n",
       "      <td>12.084479</td>\n",
       "      <td>60.546875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.774399</td>\n",
       "      <td>11.005708</td>\n",
       "      <td>22.372438</td>\n",
       "      <td>10.381601</td>\n",
       "      <td>2.032803</td>\n",
       "      <td>1.796740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>-28.774261</td>\n",
       "      <td>24.532882</td>\n",
       "      <td>94.726562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.727390</td>\n",
       "      <td>34.518932</td>\n",
       "      <td>35.727990</td>\n",
       "      <td>14.153667</td>\n",
       "      <td>1.035026</td>\n",
       "      <td>3.120821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>-30.544281</td>\n",
       "      <td>24.638541</td>\n",
       "      <td>94.726562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.577154</td>\n",
       "      <td>40.077727</td>\n",
       "      <td>28.129601</td>\n",
       "      <td>11.797667</td>\n",
       "      <td>0.701876</td>\n",
       "      <td>3.881886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-30.185699</td>\n",
       "      <td>24.519231</td>\n",
       "      <td>94.726562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>205.969303</td>\n",
       "      <td>58.371875</td>\n",
       "      <td>44.510926</td>\n",
       "      <td>10.083179</td>\n",
       "      <td>0.762541</td>\n",
       "      <td>3.528571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-34.175873</td>\n",
       "      <td>34.708590</td>\n",
       "      <td>194.824219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.456512</td>\n",
       "      <td>56.180190</td>\n",
       "      <td>35.829245</td>\n",
       "      <td>18.415697</td>\n",
       "      <td>0.637756</td>\n",
       "      <td>3.301102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-46.909332</td>\n",
       "      <td>50.691238</td>\n",
       "      <td>211.425781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>696.317715</td>\n",
       "      <td>291.979467</td>\n",
       "      <td>40.345864</td>\n",
       "      <td>21.784602</td>\n",
       "      <td>0.138180</td>\n",
       "      <td>2.384817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ch0_mean    ch0_std   ch0_range  ch0_delta   ch0_theta   ch0_alpha  \\\n",
       "0    -39.081573  12.873992   61.523438        0.0   46.851588   21.446754   \n",
       "1    -37.227631  13.884357   66.406250        0.0   32.072577   14.803212   \n",
       "2    -34.767151  16.858122   87.890625        0.0   39.094227   17.629103   \n",
       "3    -28.472900  14.586349   87.890625        0.0   20.059626   14.626256   \n",
       "4    -24.723053  12.084479   60.546875        0.0   19.774399   11.005708   \n",
       "...         ...        ...         ...        ...         ...         ...   \n",
       "1228 -28.774261  24.532882   94.726562        0.0  107.727390   34.518932   \n",
       "1229 -30.544281  24.638541   94.726562        0.0  155.577154   40.077727   \n",
       "1230 -30.185699  24.519231   94.726562        0.0  205.969303   58.371875   \n",
       "1231 -34.175873  34.708590  194.824219        0.0  185.456512   56.180190   \n",
       "1232 -46.909332  50.691238  211.425781        0.0  696.317715  291.979467   \n",
       "\n",
       "       ch0_beta  ch0_gamma  ch0_beta_alpha_ratio  ch0_theta_alpha_ratio  ...  \\\n",
       "0      9.723149  13.656038              0.453362               2.184554  ...   \n",
       "1      6.943239   7.626599              0.469036               2.166596  ...   \n",
       "2      7.657607   7.025549              0.434373               2.217596  ...   \n",
       "3     25.088838  10.495665              1.715329               1.371481  ...   \n",
       "4     22.372438  10.381601              2.032803               1.796740  ...   \n",
       "...         ...        ...                   ...                    ...  ...   \n",
       "1228  35.727990  14.153667              1.035026               3.120821  ...   \n",
       "1229  28.129601  11.797667              0.701876               3.881886  ...   \n",
       "1230  44.510926  10.083179              0.762541               3.528571  ...   \n",
       "1231  35.829245  18.415697              0.637756               3.301102  ...   \n",
       "1232  40.345864  21.784602              0.138180               2.384817  ...   \n",
       "\n",
       "      ch4_mean  ch4_std  ch4_range  ch4_delta  ch4_theta  ch4_alpha  ch4_beta  \\\n",
       "0          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "2          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "3          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "...        ...      ...        ...        ...        ...        ...       ...   \n",
       "1228       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1229       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1230       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1231       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1232       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "      ch4_gamma  ch4_beta_alpha_ratio  ch4_theta_alpha_ratio  \n",
       "0           0.0                   0.0                    0.0  \n",
       "1           0.0                   0.0                    0.0  \n",
       "2           0.0                   0.0                    0.0  \n",
       "3           0.0                   0.0                    0.0  \n",
       "4           0.0                   0.0                    0.0  \n",
       "...         ...                   ...                    ...  \n",
       "1228        0.0                   0.0                    0.0  \n",
       "1229        0.0                   0.0                    0.0  \n",
       "1230        0.0                   0.0                    0.0  \n",
       "1231        0.0                   0.0                    0.0  \n",
       "1232        0.0                   0.0                    0.0  \n",
       "\n",
       "[1233 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.drop(columns=[\"label\"])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "220ba682-2118-4cb7-83da-8f9b9a465a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1233, 50), (1233, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = train_df.values\n",
    "label_data = label_df.values\n",
    "\n",
    "training_data.shape, label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c23667-c0c0-4bd8-98b2-ff72e9a593ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (from xgboost) (2.3.3)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.28.3-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.13/site-packages (from xgboost) (1.16.2)\n",
      "Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.28.3-py3-none-manylinux_2_18_x86_64.whl (295.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.9/295.9 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [xgboost]━━━\u001b[0m \u001b[32m1/2\u001b[0m [xgboost]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-nccl-cu12-2.28.3 xgboost-3.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fbd1d6f-5898-416a-a80f-4f78efa9df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1233\n",
      "Original class distribution:\n",
      "label\n",
      "0.0    702\n",
      "1.0    531\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balancing classes...\n",
      "Balanced samples: 1062\n",
      "Balanced class distribution:\n",
      "label\n",
      "0.0    531\n",
      "1.0    531\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training set: 849\n",
      "Test set: 213\n",
      "\n",
      "Training model...\n",
      "\n",
      "==================================================\n",
      "RESULTS\n",
      "==================================================\n",
      "Training Accuracy: 1.0000 (100.00%)\n",
      "Test Accuracy: 0.9812 (98.12%)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105   2]\n",
      " [  2 104]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       107\n",
      "         1.0       0.98      0.98      0.98       106\n",
      "\n",
      "    accuracy                           0.98       213\n",
      "   macro avg       0.98      0.98      0.98       213\n",
      "weighted avg       0.98      0.98      0.98       213\n",
      "\n",
      "\n",
      "Top 10 Features:\n",
      "   feature  importance\n",
      "37  eeg_37    0.580017\n",
      "14  eeg_14    0.079389\n",
      "18  eeg_18    0.044245\n",
      "24  eeg_24    0.041944\n",
      "20  eeg_20    0.040814\n",
      "4    eeg_4    0.035679\n",
      "36  eeg_36    0.024528\n",
      "7    eeg_7    0.022520\n",
      "35  eeg_35    0.021468\n",
      "5    eeg_5    0.015926\n",
      "\n",
      "✓ Model saved to model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "# Load your data\n",
    "X_data = training_data\n",
    "y_data = label_data\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [f'eeg_{i}' for i in range(50)]\n",
    "df = pd.DataFrame(X_data, columns=columns)\n",
    "df['label'] = y_data.flatten() if y_data.ndim > 1 else y_data\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Original class distribution:\\n{y.value_counts()}\\n\")\n",
    "\n",
    "# Balance dataset by undersampling majority class\n",
    "print(\"Balancing classes...\")\n",
    "class_counts = y.value_counts()\n",
    "min_class_size = class_counts.min()\n",
    "\n",
    "# Get indices for each class\n",
    "class_0_indices = y[y == 0].index\n",
    "class_1_indices = y[y == 1].index\n",
    "\n",
    "# Randomly sample min_class_size from each class\n",
    "np.random.seed(42)\n",
    "balanced_indices_0 = np.random.choice(class_0_indices, min_class_size, replace=False)\n",
    "balanced_indices_1 = np.random.choice(class_1_indices, min_class_size, replace=False)\n",
    "\n",
    "# Combine and shuffle\n",
    "balanced_indices = np.concatenate([balanced_indices_0, balanced_indices_1])\n",
    "np.random.shuffle(balanced_indices)\n",
    "\n",
    "# Create balanced dataset\n",
    "X_balanced = X.iloc[balanced_indices]\n",
    "y_balanced = y.iloc[balanced_indices]\n",
    "\n",
    "print(f\"Balanced samples: {len(X_balanced)}\")\n",
    "print(f\"Balanced class distribution:\\n{y_balanced.value_counts()}\\n\")\n",
    "\n",
    "# Random 80/20 split with shuffle\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, shuffle=True, stratify=y_balanced\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)}\")\n",
    "print(f\"Test set: {len(X_test)}\\n\")\n",
    "\n",
    "# Train XGBoost\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Results\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Save model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(f\"\\n✓ Model saved to model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba7988cf-56df-4716-a416-8a18b13b8aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1012\n",
      "Test set size: 253\n",
      "Device: cuda\n",
      "\n",
      "Training model...\n",
      "\n",
      "Epoch [10/150]\n",
      "  Train Loss: 0.5674, Train Acc: 72.73%\n",
      "  Test Loss: 0.6490, Test Acc: 60.08%\n",
      "\n",
      "Epoch [20/150]\n",
      "  Train Loss: 0.4913, Train Acc: 73.72%\n",
      "  Test Loss: 0.5911, Test Acc: 68.38%\n",
      "\n",
      "Epoch [30/150]\n",
      "  Train Loss: 0.4456, Train Acc: 78.26%\n",
      "  Test Loss: 0.5392, Test Acc: 74.70%\n",
      "\n",
      "Epoch [40/150]\n",
      "  Train Loss: 0.3988, Train Acc: 82.51%\n",
      "  Test Loss: 0.4716, Test Acc: 80.63%\n",
      "\n",
      "Epoch [50/150]\n",
      "  Train Loss: 0.3768, Train Acc: 83.50%\n",
      "  Test Loss: 0.5657, Test Acc: 68.77%\n",
      "\n",
      "Epoch [60/150]\n",
      "  Train Loss: 0.3216, Train Acc: 84.98%\n",
      "  Test Loss: 0.4916, Test Acc: 75.89%\n",
      "\n",
      "Epoch [70/150]\n",
      "  Train Loss: 0.3182, Train Acc: 85.47%\n",
      "  Test Loss: 0.4659, Test Acc: 79.05%\n",
      "\n",
      "Epoch [80/150]\n",
      "  Train Loss: 0.3044, Train Acc: 86.96%\n",
      "  Test Loss: 0.5338, Test Acc: 71.94%\n",
      "\n",
      "Epoch [90/150]\n",
      "  Train Loss: 0.2716, Train Acc: 88.14%\n",
      "  Test Loss: 0.6746, Test Acc: 72.33%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    131\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m    132\u001b[39m loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m train_loss += loss.item()\n\u001b[32m    136\u001b[39m _, predicted = torch.max(outputs.data, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/adam.py:611\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    608\u001b[39m lr = _to_scalar(lr)\n\u001b[32m    609\u001b[39m \u001b[38;5;66;03m# TODO: Support nonzero-dim Tensor betas, see #147921\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m grouped_tensors = \u001b[43mOptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[list-item]\u001b[39;49;00m\n\u001b[32m    613\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[38;5;66;03m# We only shuffle around the beta when it is a Tensor and on CUDA, otherwise, we prefer\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[38;5;66;03m# treating it as a scalar.\u001b[39;00m\n\u001b[32m    617\u001b[39m beta1_dict: Optional[DeviceDict] = (  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    618\u001b[39m     {beta1.device: beta1}\n\u001b[32m    619\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta1, Tensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(beta1.device) != \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    621\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:545\u001b[39m, in \u001b[36mOptimizer._group_tensors_by_device_and_dtype\u001b[39m\u001b[34m(tensorlistlist, with_indices)\u001b[39m\n\u001b[32m    543\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m): (tensorlistlist, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tensorlistlist[\u001b[32m0\u001b[39m]))))}\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/utils/_foreach_utils.py:47\u001b[39m, in \u001b[36m_group_tensors_by_device_and_dtype\u001b[39m\u001b[34m(tensorlistlist, with_indices)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@no_grad\u001b[39m()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_group_tensors_by_device_and_dtype\u001b[39m(\n\u001b[32m     44\u001b[39m     tensorlistlist: TensorListList,\n\u001b[32m     45\u001b[39m     with_indices: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[torch.device, torch.dtype], \u001b[38;5;28mtuple\u001b[39m[TensorListList, Indices]]:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create column names\n",
    "columns = [f'eeg_{i}' for i in range(50)]\n",
    "\n",
    "# Create DataFrame (replace X_data and y_data with your actual arrays)\n",
    "df = pd.DataFrame(X_data, columns=columns)\n",
    "df['label'] = y_data.flatten() if y_data.ndim > 1 else y_data\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Standardize features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.LongTensor(y_train.astype(int))\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.LongTensor(y_test.astype(int))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\\n\")\n",
    "\n",
    "\n",
    "# Define a complex neural network\n",
    "class ComplexEEGNet(nn.Module):\n",
    "    def __init__(self, input_size=50, hidden_sizes=[256, 512, 256, 128, 64], dropout_rate=0.5):\n",
    "        super(ComplexEEGNet, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Build deep network with batch normalization and dropout\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, 2))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Residual connection layers (skip connections)\n",
    "        self.residual1 = nn.Linear(input_size, 256)\n",
    "        self.residual2 = nn.Linear(256, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initial input\n",
    "        identity1 = self.residual1(x)\n",
    "        \n",
    "        # First few layers\n",
    "        out = self.network[0:4](x)  # First block\n",
    "        out = out + identity1  # Skip connection\n",
    "        \n",
    "        # Middle layers\n",
    "        out = self.network[4:12](out)  # Blocks 2-3\n",
    "        identity2 = self.residual2(out)\n",
    "        \n",
    "        # Final layers\n",
    "        out = self.network[12:16](out)  # Block 4\n",
    "        out = out + identity2  # Skip connection\n",
    "        \n",
    "        # Output\n",
    "        out = self.network[16:](out)  # Final block + output\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexEEGNet().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "print(\"Training model...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    scheduler.step(avg_test_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'  Test Loss: {avg_test_loss:.4f}, Test Acc: {test_acc:.2f}%\\n')\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Results\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"FINAL RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Final Training Accuracy: {train_accs[-1]:.2f}%\")\n",
    "print(f\"Final Test Accuracy: {test_accs[-1]:.2f}%\")\n",
    "print(f\"\\nConfusion Matrix (Test Set):\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "print(f\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(train_losses, label='Train Loss', alpha=0.8)\n",
    "ax1.plot(test_losses, label='Test Loss', alpha=0.8)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(train_accs, label='Train Accuracy', alpha=0.8)\n",
    "ax2.plot(test_accs, label='Test Accuracy', alpha=0.8)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Test Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nModel Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d3ca28-947c-474b-92ed-fa8c837e4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch)\n",
      "  Downloading triton-3.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.8.0-cp313-cp313-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m  \u001b[33m0:00:24\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu127m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]ympy]]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.28.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.28.3:0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.28.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [torch]7m━\u001b[0m \u001b[32m20/21\u001b[0m [torch]2]n-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.8.0 triton-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
