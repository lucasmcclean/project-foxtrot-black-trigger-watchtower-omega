{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcab1591-efb0-4f9d-a7e9-daa4e4489d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4670b5-580f-4dd1-a82b-fedc4b7e07dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch0_mean</th>\n",
       "      <th>ch0_std</th>\n",
       "      <th>ch0_range</th>\n",
       "      <th>ch0_delta</th>\n",
       "      <th>ch0_theta</th>\n",
       "      <th>ch0_alpha</th>\n",
       "      <th>ch0_beta</th>\n",
       "      <th>ch0_gamma</th>\n",
       "      <th>ch0_beta_alpha_ratio</th>\n",
       "      <th>ch0_theta_alpha_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>ch4_std</th>\n",
       "      <th>ch4_range</th>\n",
       "      <th>ch4_delta</th>\n",
       "      <th>ch4_theta</th>\n",
       "      <th>ch4_alpha</th>\n",
       "      <th>ch4_beta</th>\n",
       "      <th>ch4_gamma</th>\n",
       "      <th>ch4_beta_alpha_ratio</th>\n",
       "      <th>ch4_theta_alpha_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-27.587891</td>\n",
       "      <td>23.112185</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.337409</td>\n",
       "      <td>6.534153</td>\n",
       "      <td>5.660460</td>\n",
       "      <td>4.652484</td>\n",
       "      <td>0.866288</td>\n",
       "      <td>3.571604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.681610</td>\n",
       "      <td>24.948808</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.608217</td>\n",
       "      <td>44.050490</td>\n",
       "      <td>11.981865</td>\n",
       "      <td>9.282773</td>\n",
       "      <td>0.272003</td>\n",
       "      <td>2.238527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.772064</td>\n",
       "      <td>24.781974</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.954611</td>\n",
       "      <td>75.076778</td>\n",
       "      <td>13.218540</td>\n",
       "      <td>10.330687</td>\n",
       "      <td>0.176067</td>\n",
       "      <td>1.717636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-32.810211</td>\n",
       "      <td>24.753504</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.903216</td>\n",
       "      <td>40.694791</td>\n",
       "      <td>8.218796</td>\n",
       "      <td>6.243245</td>\n",
       "      <td>0.201962</td>\n",
       "      <td>2.504085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.657623</td>\n",
       "      <td>24.740149</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.233400</td>\n",
       "      <td>61.910403</td>\n",
       "      <td>13.376085</td>\n",
       "      <td>11.832481</td>\n",
       "      <td>0.216056</td>\n",
       "      <td>2.362017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>-19.981384</td>\n",
       "      <td>16.545550</td>\n",
       "      <td>106.445312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.231751</td>\n",
       "      <td>14.080412</td>\n",
       "      <td>13.422488</td>\n",
       "      <td>20.430692</td>\n",
       "      <td>0.953274</td>\n",
       "      <td>2.005037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>-18.276215</td>\n",
       "      <td>14.118750</td>\n",
       "      <td>62.011719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.192710</td>\n",
       "      <td>17.438050</td>\n",
       "      <td>18.795479</td>\n",
       "      <td>23.750285</td>\n",
       "      <td>1.077843</td>\n",
       "      <td>2.075502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>-20.278931</td>\n",
       "      <td>14.925802</td>\n",
       "      <td>68.847656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.496299</td>\n",
       "      <td>19.155415</td>\n",
       "      <td>18.863969</td>\n",
       "      <td>11.615316</td>\n",
       "      <td>0.984785</td>\n",
       "      <td>2.166296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>-21.621704</td>\n",
       "      <td>14.496580</td>\n",
       "      <td>68.847656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.626045</td>\n",
       "      <td>17.453870</td>\n",
       "      <td>16.897705</td>\n",
       "      <td>21.225989</td>\n",
       "      <td>0.968135</td>\n",
       "      <td>2.728681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>-23.498535</td>\n",
       "      <td>14.539568</td>\n",
       "      <td>69.335938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.354202</td>\n",
       "      <td>14.624134</td>\n",
       "      <td>14.183944</td>\n",
       "      <td>32.851080</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>2.964565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4082 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ch0_mean    ch0_std   ch0_range  ch0_delta   ch0_theta  ch0_alpha  \\\n",
       "0    -27.587891  23.112185  120.605469        0.0   23.337409   6.534153   \n",
       "1    -30.681610  24.948808  120.605469        0.0   98.608217  44.050490   \n",
       "2    -32.772064  24.781974  120.605469        0.0  128.954611  75.076778   \n",
       "3    -32.810211  24.753504  120.605469        0.0  101.903216  40.694791   \n",
       "4    -32.657623  24.740149  120.605469        0.0  146.233400  61.910403   \n",
       "...         ...        ...         ...        ...         ...        ...   \n",
       "4077 -19.981384  16.545550  106.445312        0.0   28.231751  14.080412   \n",
       "4078 -18.276215  14.118750   62.011719        0.0   36.192710  17.438050   \n",
       "4079 -20.278931  14.925802   68.847656        0.0   41.496299  19.155415   \n",
       "4080 -21.621704  14.496580   68.847656        0.0   47.626045  17.453870   \n",
       "4081 -23.498535  14.539568   69.335938        0.0   43.354202  14.624134   \n",
       "\n",
       "       ch0_beta  ch0_gamma  ch0_beta_alpha_ratio  ch0_theta_alpha_ratio  ...  \\\n",
       "0      5.660460   4.652484              0.866288               3.571604  ...   \n",
       "1     11.981865   9.282773              0.272003               2.238527  ...   \n",
       "2     13.218540  10.330687              0.176067               1.717636  ...   \n",
       "3      8.218796   6.243245              0.201962               2.504085  ...   \n",
       "4     13.376085  11.832481              0.216056               2.362017  ...   \n",
       "...         ...        ...                   ...                    ...  ...   \n",
       "4077  13.422488  20.430692              0.953274               2.005037  ...   \n",
       "4078  18.795479  23.750285              1.077843               2.075502  ...   \n",
       "4079  18.863969  11.615316              0.984785               2.166296  ...   \n",
       "4080  16.897705  21.225989              0.968135               2.728681  ...   \n",
       "4081  14.183944  32.851080              0.969900               2.964565  ...   \n",
       "\n",
       "      ch4_std  ch4_range  ch4_delta  ch4_theta  ch4_alpha  ch4_beta  \\\n",
       "0         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "2         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "3         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4         0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "...       ...        ...        ...        ...        ...       ...   \n",
       "4077      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4078      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4079      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4080      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4081      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "      ch4_gamma  ch4_beta_alpha_ratio  ch4_theta_alpha_ratio  label  \n",
       "0           0.0                   0.0                    0.0    0.0  \n",
       "1           0.0                   0.0                    0.0    0.0  \n",
       "2           0.0                   0.0                    0.0    0.0  \n",
       "3           0.0                   0.0                    0.0    0.0  \n",
       "4           0.0                   0.0                    0.0    0.0  \n",
       "...         ...                   ...                    ...    ...  \n",
       "4077        0.0                   0.0                    0.0    3.0  \n",
       "4078        0.0                   0.0                    0.0    3.0  \n",
       "4079        0.0                   0.0                    0.0    3.0  \n",
       "4080        0.0                   0.0                    0.0    3.0  \n",
       "4081        0.0                   0.0                    0.0    3.0  \n",
       "\n",
       "[4082 rows x 51 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"eeg_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6265cdbf-9a32-4925-b613-7c989c2857f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4082 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "...     ...\n",
       "4077    3.0\n",
       "4078    3.0\n",
       "4079    3.0\n",
       "4080    3.0\n",
       "4081    3.0\n",
       "\n",
       "[4082 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = df[[\"label\"]]\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e871669-a6c0-49f6-bcff-adaf0c79dc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ch0_mean</th>\n",
       "      <th>ch0_std</th>\n",
       "      <th>ch0_range</th>\n",
       "      <th>ch0_delta</th>\n",
       "      <th>ch0_theta</th>\n",
       "      <th>ch0_alpha</th>\n",
       "      <th>ch0_beta</th>\n",
       "      <th>ch0_gamma</th>\n",
       "      <th>ch0_beta_alpha_ratio</th>\n",
       "      <th>ch0_theta_alpha_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>ch4_mean</th>\n",
       "      <th>ch4_std</th>\n",
       "      <th>ch4_range</th>\n",
       "      <th>ch4_delta</th>\n",
       "      <th>ch4_theta</th>\n",
       "      <th>ch4_alpha</th>\n",
       "      <th>ch4_beta</th>\n",
       "      <th>ch4_gamma</th>\n",
       "      <th>ch4_beta_alpha_ratio</th>\n",
       "      <th>ch4_theta_alpha_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-27.587891</td>\n",
       "      <td>23.112185</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.337409</td>\n",
       "      <td>6.534153</td>\n",
       "      <td>5.660460</td>\n",
       "      <td>4.652484</td>\n",
       "      <td>0.866288</td>\n",
       "      <td>3.571604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-30.681610</td>\n",
       "      <td>24.948808</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.608217</td>\n",
       "      <td>44.050490</td>\n",
       "      <td>11.981865</td>\n",
       "      <td>9.282773</td>\n",
       "      <td>0.272003</td>\n",
       "      <td>2.238527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.772064</td>\n",
       "      <td>24.781974</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.954611</td>\n",
       "      <td>75.076778</td>\n",
       "      <td>13.218540</td>\n",
       "      <td>10.330687</td>\n",
       "      <td>0.176067</td>\n",
       "      <td>1.717636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-32.810211</td>\n",
       "      <td>24.753504</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.903216</td>\n",
       "      <td>40.694791</td>\n",
       "      <td>8.218796</td>\n",
       "      <td>6.243245</td>\n",
       "      <td>0.201962</td>\n",
       "      <td>2.504085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.657623</td>\n",
       "      <td>24.740149</td>\n",
       "      <td>120.605469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.233400</td>\n",
       "      <td>61.910403</td>\n",
       "      <td>13.376085</td>\n",
       "      <td>11.832481</td>\n",
       "      <td>0.216056</td>\n",
       "      <td>2.362017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>-19.981384</td>\n",
       "      <td>16.545550</td>\n",
       "      <td>106.445312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.231751</td>\n",
       "      <td>14.080412</td>\n",
       "      <td>13.422488</td>\n",
       "      <td>20.430692</td>\n",
       "      <td>0.953274</td>\n",
       "      <td>2.005037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>-18.276215</td>\n",
       "      <td>14.118750</td>\n",
       "      <td>62.011719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.192710</td>\n",
       "      <td>17.438050</td>\n",
       "      <td>18.795479</td>\n",
       "      <td>23.750285</td>\n",
       "      <td>1.077843</td>\n",
       "      <td>2.075502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>-20.278931</td>\n",
       "      <td>14.925802</td>\n",
       "      <td>68.847656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.496299</td>\n",
       "      <td>19.155415</td>\n",
       "      <td>18.863969</td>\n",
       "      <td>11.615316</td>\n",
       "      <td>0.984785</td>\n",
       "      <td>2.166296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>-21.621704</td>\n",
       "      <td>14.496580</td>\n",
       "      <td>68.847656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.626045</td>\n",
       "      <td>17.453870</td>\n",
       "      <td>16.897705</td>\n",
       "      <td>21.225989</td>\n",
       "      <td>0.968135</td>\n",
       "      <td>2.728681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>-23.498535</td>\n",
       "      <td>14.539568</td>\n",
       "      <td>69.335938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.354202</td>\n",
       "      <td>14.624134</td>\n",
       "      <td>14.183944</td>\n",
       "      <td>32.851080</td>\n",
       "      <td>0.969900</td>\n",
       "      <td>2.964565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4082 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ch0_mean    ch0_std   ch0_range  ch0_delta   ch0_theta  ch0_alpha  \\\n",
       "0    -27.587891  23.112185  120.605469        0.0   23.337409   6.534153   \n",
       "1    -30.681610  24.948808  120.605469        0.0   98.608217  44.050490   \n",
       "2    -32.772064  24.781974  120.605469        0.0  128.954611  75.076778   \n",
       "3    -32.810211  24.753504  120.605469        0.0  101.903216  40.694791   \n",
       "4    -32.657623  24.740149  120.605469        0.0  146.233400  61.910403   \n",
       "...         ...        ...         ...        ...         ...        ...   \n",
       "4077 -19.981384  16.545550  106.445312        0.0   28.231751  14.080412   \n",
       "4078 -18.276215  14.118750   62.011719        0.0   36.192710  17.438050   \n",
       "4079 -20.278931  14.925802   68.847656        0.0   41.496299  19.155415   \n",
       "4080 -21.621704  14.496580   68.847656        0.0   47.626045  17.453870   \n",
       "4081 -23.498535  14.539568   69.335938        0.0   43.354202  14.624134   \n",
       "\n",
       "       ch0_beta  ch0_gamma  ch0_beta_alpha_ratio  ch0_theta_alpha_ratio  ...  \\\n",
       "0      5.660460   4.652484              0.866288               3.571604  ...   \n",
       "1     11.981865   9.282773              0.272003               2.238527  ...   \n",
       "2     13.218540  10.330687              0.176067               1.717636  ...   \n",
       "3      8.218796   6.243245              0.201962               2.504085  ...   \n",
       "4     13.376085  11.832481              0.216056               2.362017  ...   \n",
       "...         ...        ...                   ...                    ...  ...   \n",
       "4077  13.422488  20.430692              0.953274               2.005037  ...   \n",
       "4078  18.795479  23.750285              1.077843               2.075502  ...   \n",
       "4079  18.863969  11.615316              0.984785               2.166296  ...   \n",
       "4080  16.897705  21.225989              0.968135               2.728681  ...   \n",
       "4081  14.183944  32.851080              0.969900               2.964565  ...   \n",
       "\n",
       "      ch4_mean  ch4_std  ch4_range  ch4_delta  ch4_theta  ch4_alpha  ch4_beta  \\\n",
       "0          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "1          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "2          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "3          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4          0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "...        ...      ...        ...        ...        ...        ...       ...   \n",
       "4077       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4078       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4079       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4080       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "4081       0.0      0.0        0.0        0.0        0.0        0.0       0.0   \n",
       "\n",
       "      ch4_gamma  ch4_beta_alpha_ratio  ch4_theta_alpha_ratio  \n",
       "0           0.0                   0.0                    0.0  \n",
       "1           0.0                   0.0                    0.0  \n",
       "2           0.0                   0.0                    0.0  \n",
       "3           0.0                   0.0                    0.0  \n",
       "4           0.0                   0.0                    0.0  \n",
       "...         ...                   ...                    ...  \n",
       "4077        0.0                   0.0                    0.0  \n",
       "4078        0.0                   0.0                    0.0  \n",
       "4079        0.0                   0.0                    0.0  \n",
       "4080        0.0                   0.0                    0.0  \n",
       "4081        0.0                   0.0                    0.0  \n",
       "\n",
       "[4082 rows x 50 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.drop(columns=[\"label\"])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220ba682-2118-4cb7-83da-8f9b9a465a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4082, 50), (4082, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = train_df.values\n",
    "label_data = label_df.values\n",
    "\n",
    "training_data.shape, label_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c23667-c0c0-4bd8-98b2-ff72e9a593ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/rhygon/Desktop/projects/muse/.venv/lib/python3.13/site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in /home/rhygon/Desktop/projects/muse/.venv/lib/python3.13/site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/rhygon/Desktop/projects/muse/.venv/lib/python3.13/site-packages (from xgboost) (2.28.7)\n",
      "Requirement already satisfied: scipy in /home/rhygon/Desktop/projects/muse/.venv/lib/python3.13/site-packages (from xgboost) (1.16.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fbd1d6f-5898-416a-a80f-4f78efa9df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 4082\n",
      "Original class distribution:\n",
      "label\n",
      "0.0    1024\n",
      "1.0    1017\n",
      "2.0    1005\n",
      "3.0    1036\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balancing classes...\n",
      "Balanced samples: 4020\n",
      "Balanced class distribution:\n",
      "label\n",
      "0.0    1005\n",
      "1.0    1005\n",
      "2.0    1005\n",
      "3.0    1005\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training set: 3216\n",
      "Test set: 804\n",
      "Training class distribution:\n",
      "label\n",
      "0.0    804\n",
      "1.0    804\n",
      "2.0    804\n",
      "3.0    804\n",
      "Name: count, dtype: int64\n",
      "Test class distribution:\n",
      "label\n",
      "0.0    201\n",
      "1.0    201\n",
      "2.0    201\n",
      "3.0    201\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training model...\n",
      "\n",
      "==================================================\n",
      "RESULTS\n",
      "==================================================\n",
      "Training Accuracy: 0.9966 (99.66%)\n",
      "Test Accuracy: 0.9789 (97.89%)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[196   3   1   1]\n",
      " [  4 195   0   2]\n",
      " [  2   0 198   1]\n",
      " [  1   1   1 198]]\n",
      "\n",
      "Confusion Matrix (formatted):\n",
      "Predicted →\n",
      "Actual ↓   Class     0  Class     1  Class     2  Class     3  \n",
      "Class 0       196        3        1        1  \n",
      "Class 1         4      195        0        2  \n",
      "Class 2         2        0      198        1  \n",
      "Class 3         1        1        1      198  \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.97      0.98      0.97       201\n",
      "     Class 1       0.98      0.97      0.97       201\n",
      "     Class 2       0.99      0.99      0.99       201\n",
      "     Class 3       0.98      0.99      0.98       201\n",
      "\n",
      "    accuracy                           0.98       804\n",
      "   macro avg       0.98      0.98      0.98       804\n",
      "weighted avg       0.98      0.98      0.98       804\n",
      "\n",
      "\n",
      "Top 10 Features:\n",
      "   feature  importance\n",
      "17  eeg_17    0.181296\n",
      "37  eeg_37    0.150852\n",
      "36  eeg_36    0.099424\n",
      "12  eeg_12    0.058541\n",
      "27  eeg_27    0.055516\n",
      "16  eeg_16    0.038283\n",
      "7    eeg_7    0.034508\n",
      "26  eeg_26    0.026683\n",
      "0    eeg_0    0.025198\n",
      "22  eeg_22    0.025069\n",
      "\n",
      "Per-Class Accuracy:\n",
      "  Class 0: 0.9751 (97.51%)\n",
      "  Class 1: 0.9701 (97.01%)\n",
      "  Class 2: 0.9851 (98.51%)\n",
      "  Class 3: 0.9851 (98.51%)\n",
      "\n",
      "✓ Model saved to model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "# Load your data\n",
    "X_data = training_data\n",
    "y_data = label_data\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [f'eeg_{i}' for i in range(50)]\n",
    "df = pd.DataFrame(X_data, columns=columns)\n",
    "df['label'] = y_data.flatten() if y_data.ndim > 1 else y_data\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Original class distribution:\\n{y.value_counts().sort_index()}\\n\")\n",
    "\n",
    "# Balance dataset by undersampling majority classes\n",
    "print(\"Balancing classes...\")\n",
    "class_counts = y.value_counts()\n",
    "min_class_size = class_counts.min()\n",
    "\n",
    "# Get indices for each class (0, 1, 2, 3)\n",
    "class_indices = {cls: y[y == cls].index for cls in range(4)}\n",
    "\n",
    "# Randomly sample min_class_size from each class\n",
    "np.random.seed(42)\n",
    "balanced_indices_list = []\n",
    "for cls in range(4):\n",
    "    sampled = np.random.choice(class_indices[cls], min_class_size, replace=False)\n",
    "    balanced_indices_list.append(sampled)\n",
    "\n",
    "# Combine and shuffle\n",
    "balanced_indices = np.concatenate(balanced_indices_list)\n",
    "np.random.shuffle(balanced_indices)\n",
    "\n",
    "# Create balanced dataset\n",
    "X_balanced = X.iloc[balanced_indices]\n",
    "y_balanced = y.iloc[balanced_indices]\n",
    "\n",
    "print(f\"Balanced samples: {len(X_balanced)}\")\n",
    "print(f\"Balanced class distribution:\\n{y_balanced.value_counts().sort_index()}\\n\")\n",
    "\n",
    "# Random 80/20 split with shuffle\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, shuffle=True, stratify=y_balanced\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)}\")\n",
    "print(f\"Test set: {len(X_test)}\")\n",
    "print(f\"Training class distribution:\\n{y_train.value_counts().sort_index()}\")\n",
    "print(f\"Test class distribution:\\n{y_test.value_counts().sort_index()}\\n\")\n",
    "\n",
    "# Train XGBoost for multi-class classification\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=3,  # Slightly increased for more complex patterns\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    objective='multi:softmax',  # Multi-class classification\n",
    "    num_class=4,  # 4 classes\n",
    "    eval_metric='mlogloss'  # Multi-class log loss\n",
    ")\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Results\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(cm)\n",
    "\n",
    "# Pretty print confusion matrix\n",
    "print(\"\\nConfusion Matrix (formatted):\")\n",
    "print(\"Predicted →\")\n",
    "print(\"Actual ↓   \", end=\"\")\n",
    "for i in range(4):\n",
    "    print(f\"Class {i:>5}\", end=\"  \")\n",
    "print()\n",
    "for i in range(4):\n",
    "    print(f\"Class {i}   \", end=\"\")\n",
    "    for j in range(4):\n",
    "        print(f\"{cm[i][j]:>7}\", end=\"  \")\n",
    "    print()\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=[f'Class {i}' for i in range(4)]))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "for cls in range(4):\n",
    "    mask = y_test == cls\n",
    "    if mask.sum() > 0:\n",
    "        cls_acc = accuracy_score(y_test[mask], y_pred_test[mask])\n",
    "        print(f\"  Class {cls}: {cls_acc:.4f} ({cls_acc*100:.2f}%)\")\n",
    "\n",
    "# Save model\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(f\"\\n✓ Model saved to model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba7988cf-56df-4716-a416-8a18b13b8aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1012\n",
      "Test set size: 253\n",
      "Device: cuda\n",
      "\n",
      "Training model...\n",
      "\n",
      "Epoch [10/150]\n",
      "  Train Loss: 0.5674, Train Acc: 72.73%\n",
      "  Test Loss: 0.6490, Test Acc: 60.08%\n",
      "\n",
      "Epoch [20/150]\n",
      "  Train Loss: 0.4913, Train Acc: 73.72%\n",
      "  Test Loss: 0.5911, Test Acc: 68.38%\n",
      "\n",
      "Epoch [30/150]\n",
      "  Train Loss: 0.4456, Train Acc: 78.26%\n",
      "  Test Loss: 0.5392, Test Acc: 74.70%\n",
      "\n",
      "Epoch [40/150]\n",
      "  Train Loss: 0.3988, Train Acc: 82.51%\n",
      "  Test Loss: 0.4716, Test Acc: 80.63%\n",
      "\n",
      "Epoch [50/150]\n",
      "  Train Loss: 0.3768, Train Acc: 83.50%\n",
      "  Test Loss: 0.5657, Test Acc: 68.77%\n",
      "\n",
      "Epoch [60/150]\n",
      "  Train Loss: 0.3216, Train Acc: 84.98%\n",
      "  Test Loss: 0.4916, Test Acc: 75.89%\n",
      "\n",
      "Epoch [70/150]\n",
      "  Train Loss: 0.3182, Train Acc: 85.47%\n",
      "  Test Loss: 0.4659, Test Acc: 79.05%\n",
      "\n",
      "Epoch [80/150]\n",
      "  Train Loss: 0.3044, Train Acc: 86.96%\n",
      "  Test Loss: 0.5338, Test Acc: 71.94%\n",
      "\n",
      "Epoch [90/150]\n",
      "  Train Loss: 0.2716, Train Acc: 88.14%\n",
      "  Test Loss: 0.6746, Test Acc: 72.33%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 133\u001b[39m\n\u001b[32m    131\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m    132\u001b[39m loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m train_loss += loss.item()\n\u001b[32m    136\u001b[39m _, predicted = torch.max(outputs.data, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:516\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    513\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:81\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     80\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:149\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/adam.py:949\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/adam.py:611\u001b[39m, in \u001b[36m_multi_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    608\u001b[39m lr = _to_scalar(lr)\n\u001b[32m    609\u001b[39m \u001b[38;5;66;03m# TODO: Support nonzero-dim Tensor betas, see #147921\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m grouped_tensors = \u001b[43mOptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[list-item]\u001b[39;49;00m\n\u001b[32m    613\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[38;5;66;03m# We only shuffle around the beta when it is a Tensor and on CUDA, otherwise, we prefer\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[38;5;66;03m# treating it as a scalar.\u001b[39;00m\n\u001b[32m    617\u001b[39m beta1_dict: Optional[DeviceDict] = (  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    618\u001b[39m     {beta1.device: beta1}\n\u001b[32m    619\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(beta1, Tensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(beta1.device) != \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    621\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:545\u001b[39m, in \u001b[36mOptimizer._group_tensors_by_device_and_dtype\u001b[39m\u001b[34m(tensorlistlist, with_indices)\u001b[39m\n\u001b[32m    543\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m): (tensorlistlist, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tensorlistlist[\u001b[32m0\u001b[39m]))))}\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/projects/muse/.venv/lib/python3.13/site-packages/torch/utils/_foreach_utils.py:47\u001b[39m, in \u001b[36m_group_tensors_by_device_and_dtype\u001b[39m\u001b[34m(tensorlistlist, with_indices)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@no_grad\u001b[39m()\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_group_tensors_by_device_and_dtype\u001b[39m(\n\u001b[32m     44\u001b[39m     tensorlistlist: TensorListList,\n\u001b[32m     45\u001b[39m     with_indices: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[torch.device, torch.dtype], \u001b[38;5;28mtuple\u001b[39m[TensorListList, Indices]]:\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_group_tensors_by_device_and_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensorlistlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create column names\n",
    "columns = [f'eeg_{i}' for i in range(50)]\n",
    "\n",
    "# Create DataFrame (replace X_data and y_data with your actual arrays)\n",
    "df = pd.DataFrame(X_data, columns=columns)\n",
    "df['label'] = y_data.flatten() if y_data.ndim > 1 else y_data\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('label', axis=1).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Standardize features (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.LongTensor(y_train.astype(int))\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.LongTensor(y_test.astype(int))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\\n\")\n",
    "\n",
    "\n",
    "# Define a complex neural network\n",
    "class ComplexEEGNet(nn.Module):\n",
    "    def __init__(self, input_size=50, hidden_sizes=[256, 512, 256, 128, 64], dropout_rate=0.5):\n",
    "        super(ComplexEEGNet, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Build deep network with batch normalization and dropout\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, 2))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Residual connection layers (skip connections)\n",
    "        self.residual1 = nn.Linear(input_size, 256)\n",
    "        self.residual2 = nn.Linear(256, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initial input\n",
    "        identity1 = self.residual1(x)\n",
    "        \n",
    "        # First few layers\n",
    "        out = self.network[0:4](x)  # First block\n",
    "        out = out + identity1  # Skip connection\n",
    "        \n",
    "        # Middle layers\n",
    "        out = self.network[4:12](out)  # Blocks 2-3\n",
    "        identity2 = self.residual2(out)\n",
    "        \n",
    "        # Final layers\n",
    "        out = self.network[12:16](out)  # Block 4\n",
    "        out = out + identity2  # Skip connection\n",
    "        \n",
    "        # Output\n",
    "        out = self.network[16:](out)  # Final block + output\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexEEGNet().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "print(\"Training model...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    test_losses.append(avg_test_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    scheduler.step(avg_test_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'  Test Loss: {avg_test_loss:.4f}, Test Acc: {test_acc:.2f}%\\n')\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Results\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"FINAL RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Final Training Accuracy: {train_accs[-1]:.2f}%\")\n",
    "print(f\"Final Test Accuracy: {test_accs[-1]:.2f}%\")\n",
    "print(f\"\\nConfusion Matrix (Test Set):\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "print(f\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(train_losses, label='Train Loss', alpha=0.8)\n",
    "ax1.plot(test_losses, label='Test Loss', alpha=0.8)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Test Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(train_accs, label='Train Accuracy', alpha=0.8)\n",
    "ax2.plot(test_accs, label='Test Accuracy', alpha=0.8)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training and Test Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nModel Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d3ca28-947c-474b-92ed-fa8c837e4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch)\n",
      "  Downloading triton-3.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading torch-2.8.0-cp313-cp313-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m  \u001b[33m0:00:24\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m  \u001b[33m0:00:16\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.4.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu127m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]ympy]]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.28.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.28.3:0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.28.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/21\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [torch]7m━\u001b[0m \u001b[32m20/21\u001b[0m [torch]2]n-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.8.0 triton-3.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
